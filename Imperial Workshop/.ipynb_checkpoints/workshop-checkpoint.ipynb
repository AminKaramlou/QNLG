{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33swP5fD5dpx",
    "tags": []
   },
   "source": [
    "# Sentence Generation on Quantum Computers\n",
    "\n",
    "In this workshop we're going to generate some sentences about food, using the techniques in the paper \"Quantum Natural Language Generation on Near-Term devices\". \n",
    "\n",
    "The first part of this notebook is based on the following example from Lambeq, a python library specifically created for QNLP tasks: https://cqcl.github.io/lambeq/examples/quantum_pipeline.html. We encourage you to explore Lambeq more after this workshop, it has lots of neat features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeOh_GGg5dp4"
   },
   "source": [
    "## Installing the dependencies\n",
    "The first thing we need to do is make sure we have the necessary python packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KPvszq_5dp5",
    "outputId": "16640c53-6bcc-4d43-aa7d-471b22e72e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lambeq\n",
      "  Using cached lambeq-0.2.3-py3-none-any.whl (122 kB)\n",
      "Collecting tensornetwork\n",
      "  Using cached tensornetwork-0.4.6-py3-none-any.whl (364 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
      "Collecting spacy>=3.0\n",
      "  Using cached spacy-3.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "Requirement already satisfied: torch>=1.10.1 in /opt/conda/lib/python3.8/site-packages (from lambeq) (1.11.0+rocm4.5.2)\n",
      "Collecting pytket>=0.19.2\n",
      "  Using cached pytket-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "Collecting discopy>=0.4.2\n",
      "  Using cached discopy-0.4.2-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from lambeq) (6.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.2 in /opt/conda/lib/python3.8/site-packages (from discopy>=0.4.2->lambeq) (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.1 in /opt/conda/lib/python3.8/site-packages (from discopy>=0.4.2->lambeq) (9.0.1)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.8/site-packages (from discopy>=0.4.2->lambeq) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.8/site-packages (from discopy>=0.4.2->lambeq) (1.21.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (4.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.2->discopy>=0.4.2->lambeq) (1.16.0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.7.2 in /opt/conda/lib/python3.8/site-packages (from pytket>=0.19.2->lambeq) (1.8.0)\n",
      "Collecting lark-parser~=0.7\n",
      "  Using cached lark_parser-0.12.0-py2.py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: jinja2~=3.0 in /opt/conda/lib/python3.8/site-packages (from pytket>=0.19.2->lambeq) (3.0.3)\n",
      "Collecting types-pkg-resources\n",
      "  Using cached types_pkg_resources-0.1.3-py2.py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: sympy~=1.6 in /opt/conda/lib/python3.8/site-packages (from pytket>=0.19.2->lambeq) (1.10.1)\n",
      "Requirement already satisfied: graphviz~=0.14 in /opt/conda/lib/python3.8/site-packages (from pytket>=0.19.2->lambeq) (0.20)\n",
      "Requirement already satisfied: typing-extensions~=4.2 in /opt/conda/lib/python3.8/site-packages (from pytket>=0.19.2->lambeq) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2~=3.0->pytket>=0.19.2->lambeq) (2.1.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy>=3.0->lambeq) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy>=3.0->lambeq) (4.64.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy>=3.0->lambeq) (61.2.0)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Using cached thinc-8.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->lambeq) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->lambeq) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->lambeq) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->lambeq) (1.26.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy~=1.6->pytket>=0.19.2->lambeq) (1.2.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0->lambeq) (8.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensornetwork->lambeq) (3.6.0)\n",
      "Collecting opt-einsum>=2.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, filelock, blis, types-pkg-resources, tokenizers, thinc, spacy-loggers, spacy-legacy, regex, pathy, opt-einsum, lark-parser, langcodes, huggingface-hub, transformers, tensornetwork, spacy, pytket, discopy, lambeq\n",
      "Successfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 discopy-0.4.2 filelock-3.7.1 huggingface-hub-0.7.0 lambeq-0.2.3 langcodes-3.3.0 lark-parser-0.12.0 murmurhash-1.0.7 opt-einsum-3.3.0 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 pytket-1.3.0 regex-2022.6.2 smart-open-5.2.1 spacy-3.3.1 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 tensornetwork-0.4.6 thinc-8.0.17 tokenizers-0.12.1 transformers-4.20.0 typer-0.4.1 types-pkg-resources-0.1.3 wasabi-0.9.1\n",
      "Collecting pytket-qiskit\n",
      "  Using cached pytket_qiskit-0.26.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pytket~=1.3 in /opt/conda/lib/python3.8/site-packages (from pytket-qiskit) (1.3.0)\n",
      "Requirement already satisfied: qiskit~=0.36.0 in /opt/conda/lib/python3.8/site-packages (from pytket-qiskit) (0.36.2)\n",
      "Requirement already satisfied: networkx~=2.4 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (2.7.1)\n",
      "Requirement already satisfied: types-pkg-resources in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (0.1.3)\n",
      "Requirement already satisfied: typing-extensions~=4.2 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (4.2.0)\n",
      "Requirement already satisfied: lark-parser~=0.7 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (0.12.0)\n",
      "Requirement already satisfied: graphviz~=0.14 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (0.20)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.4 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (1.21.5)\n",
      "Requirement already satisfied: scipy<2.0,>=1.7.2 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (1.8.0)\n",
      "Requirement already satisfied: jinja2~=3.0 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (3.0.3)\n",
      "Requirement already satisfied: sympy~=1.6 in /opt/conda/lib/python3.8/site-packages (from pytket~=1.3->pytket-qiskit) (1.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2~=3.0->pytket~=1.3->pytket-qiskit) (2.1.1)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.19.1 in /opt/conda/lib/python3.8/site-packages (from qiskit~=0.36.0->pytket-qiskit) (0.19.1)\n",
      "Requirement already satisfied: qiskit-ignis==0.7.1 in /opt/conda/lib/python3.8/site-packages (from qiskit~=0.36.0->pytket-qiskit) (0.7.1)\n",
      "Requirement already satisfied: qiskit-terra==0.20.2 in /opt/conda/lib/python3.8/site-packages (from qiskit~=0.36.0->pytket-qiskit) (0.20.2)\n",
      "Requirement already satisfied: qiskit-aer==0.10.4 in /opt/conda/lib/python3.8/site-packages (from qiskit~=0.36.0->pytket-qiskit) (0.10.4)\n",
      "Requirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (10.3)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.1.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (2.8.2)\n",
      "Requirement already satisfied: websocket-client>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.3.2)\n",
      "Requirement already satisfied: requests>=2.19 in /opt/conda/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (2.27.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-ignis==0.7.1->qiskit~=0.36.0->pytket-qiskit) (61.2.0)\n",
      "Requirement already satisfied: retworkx>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-ignis==0.7.1->qiskit~=0.36.0->pytket-qiskit) (0.11.0)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (0.3.4)\n",
      "Requirement already satisfied: symengine>=0.9 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (0.9.2)\n",
      "Requirement already satisfied: python-constraint>=1.4 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (1.4.0)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (3.11)\n",
      "Requirement already satisfied: tweedledum<2.0,>=1.1 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (1.1.1)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (5.9.0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (2.0.12)\n",
      "Requirement already satisfied: cryptography>=1.3 in /opt/conda/lib/python3.8/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (36.0.2)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.8/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit~=0.36.0->pytket-qiskit) (2.21)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from stevedore>=3.0.0->qiskit-terra==0.20.2->qiskit~=0.36.0->pytket-qiskit) (5.8.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy~=1.6->pytket~=1.3->pytket-qiskit) (1.2.1)\n",
      "Installing collected packages: pytket-qiskit\n",
      "Successfully installed pytket-qiskit-0.26.0\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (8.1.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.7\n"
     ]
    }
   ],
   "source": [
    "! pip install lambeq\n",
    "! pip install pytket-qiskit\n",
    "! pip install nltk\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kzh6eLX5dp8"
   },
   "source": [
    "## Step 1: Read in the data and create diagrams\n",
    "\n",
    "To begin with, we are going to read in the 130 sentences stored in the dataset directory. Each senetence has been assigned As is standard in machine learning, these sentences are split into training, validation (dev), and development datasets. Don't worry if you don't know what this terminology means, it won't be terribly important for what follows. If you want more information you can checkout: https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#Validation_data_set\n",
    "\n",
    "Now it's time for your first assignment in this workshop:\n",
    "### Assigment 1: Fix the code below so that the test dataset is loaded into the appropriate variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZSfSD3R5dp9"
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            t = int(line[0])\n",
    "            labels.append([t, 1-t])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return labels, sentences\n",
    "\n",
    "\n",
    "train_labels, train_data = read_data('datasets/mc_train_data.txt')\n",
    "dev_labels, dev_data = read_data('datasets/mc_dev_data.txt')\n",
    "test_labels, test_data = read_data('????????????')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC0-oiMz5dqA"
   },
   "source": [
    "## Step 2: Parsing and Diagram creation\n",
    "\n",
    "We now want to turn each sentence in the dataset into a parameterised quantum circuit which encodes it's meaning. We begin doing this by parsing the sentences and generating their corresponding DisCoCat diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgu1vdBX5dqC",
    "outputId": "75e77789-eac0-4dda-8a1f-c347cb3da7e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n",
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n",
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n"
     ]
    }
   ],
   "source": [
    "from lambeq import BobcatParser\n",
    "\n",
    "parser = BobcatParser(verbose='text')\n",
    "\n",
    "raw_train_diagrams = parser.sentences2diagrams(train_data)\n",
    "raw_train_diagrams[0].draw()\n",
    "raw_dev_diagrams = parser.sentences2diagrams(dev_data)\n",
    "raw_dev_diagrams[0].draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNTv2EGp5dqD"
   },
   "source": [
    "### Assignment 2: Complete the code below in order to generate diagrams for the test_dataset. Then draw one of these diagrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qte-gbgr5dqE"
   },
   "outputs": [],
   "source": [
    "raw_test_diagrams = ?????????\n",
    "?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6nnyZLG5dqE"
   },
   "source": [
    "## Step 3: Diagrma Rewriting\n",
    "\n",
    "Now it's time for the optional diagram rewriting step. We are going to remove all the cups in the diagram (Run the cell below to see what we mean). This is a helpful rewrite since it means that the quantum circuits we eventually end up with in the end can be implemented with less qubits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1AzYfKp5dqF",
    "outputId": "2f16f75b-d2e9-4027-c188-62834209d389"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lambeq import remove_cups\n",
    "\n",
    "print(\"Before removing cups\")\n",
    "raw_train_diagrams[0].draw()\n",
    "train_diagrams = [remove_cups(diagram) for diagram in raw_train_diagrams]\n",
    "print(\"After removing cups\")\n",
    "train_diagrams[0].draw()\n",
    "\n",
    "dev_diagrams = [remove_cups(diagram) for diagram in raw_dev_diagrams]\n",
    "dev_diagrams[0].draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfBc_Gre5dqG"
   },
   "source": [
    "### Assignment 3: Remove the cups from the test_diagrams and draw one of the new diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4PNZHvG5dqH"
   },
   "outputs": [],
   "source": [
    "test_diagrams = ????\n",
    "????\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hupW4knN5dqH"
   },
   "source": [
    "## Step 4: Create Parameterised Quantum Circuit \n",
    "\n",
    "We are finally ready to create our parameterised quantum circuit. In order to do this we will use lambeqs IQPAnsatz (See https://cqcl.github.io/lambeq/tutorials/parameterise.html for more info). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tix1Y105dqI"
   },
   "outputs": [],
   "source": [
    "from lambeq import AtomicType, IQPAnsatz\n",
    "\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},\n",
    "                   n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "train_circuits[0].draw(figsize=(9, 12))\n",
    "dev_circuits =  [ansatz(diagram) for diagram in dev_diagrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNuxNHAA5dqI"
   },
   "source": [
    "### Assignment 4: Use the ansatz function to transform the testing diagrams into parameterised quantum circuits. Draw one of these quantum circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hAmN8uV5dqJ",
    "outputId": "c6506d15-6eaf-427c-da63-ac72d0008a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  File \u001b[1;32m/opt/conda/lib/python3.8/site-packages/IPython/core/compilerop.py:105\u001b[1;36m in \u001b[1;35mast_parse\u001b[1;36m\u001b[0m\n",
      "\u001b[1;33m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n",
      "\u001b[1;33m    test_circuits = ????\u001b[0m\n",
      "\u001b[1;37m                    ^\u001b[0m\n",
      "\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n",
      "\n",
      "Use %tb to get the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".button {\n",
       "  border: none;\n",
       "  color: white;\n",
       "  padding: 4px 8px;\n",
       "  text-align: center;\n",
       "  text-decoration: none;\n",
       "  display: inline-block;\n",
       "  font-size: 12px;\n",
       "  margin: 4px 2px;\n",
       "  transition-duration: 0.2s;\n",
       "  cursor: pointer;\n",
       "}\n",
       ".iqx-button {\n",
       "  background-color: #0f62fe; \n",
       "  color: white; \n",
       "}\n",
       ".iqx-button:hover {\n",
       "  background-color: #0043ce;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<a href=\"https://stackoverflow.com/search?q=SyntaxError: invalid syntax\" target='_blank'><button class='button iqx-button'>Search for solution online</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_circuits = ????\n",
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQu2fk8k5dqK"
   },
   "source": [
    "# Step 5: Choosing a backend\n",
    "We are now going to choose a backend on which our quantum circuits is going to be run. In this workshop we are going to use a classical simulator (a classical computer which simulates the bahaviour of a real quantum computer) to run our circuits. \n",
    "\n",
    "The IBM Quantum Experience does allow us to run this code on real quantum computers as well. However, given that access to quantum computers is currently in high demand this won't be feasible to do during the workshop, since we'd spent the whole time queuing and waiting for our circuits to be executed. So you have some homework:\n",
    "\n",
    "### Homework: Read through the pytket and qiskit documentation and try changing the code to use a real quantum computer as a backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbAv3-O75dqL"
   },
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel\n",
    "\n",
    "all_circuits = train_circuits+dev_circuits+test_circuits\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 8192\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXneWmYr5dqN"
   },
   "source": [
    "# Step 6: Creating the quantum sentence classifier. \n",
    "\n",
    "The code below trains our quantum sentence classifier. Since the training can take a few minutes we could alternatively work with a pre-trained model which you can load from the `checkpoint.pickle` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4DGOBBP5dqO"
   },
   "outputs": [],
   "source": [
    "model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)\n",
    "\n",
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "\n",
    "EPOCHS = 120\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.05, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "from lambeq import Dataset\n",
    "\n",
    "train_dataset = Dataset(\n",
    "            train_circuits,\n",
    "            train_labels,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = Dataset(dev_circuits, dev_labels, shuffle=False)\n",
    "trainer.fit(train_dataset, val_dataset, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGdV9TRm5dqP"
   },
   "outputs": [],
   "source": [
    "# model = TketModel.from_checkpoint('checkpoint.pickle', backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-fjpkfT5dqQ"
   },
   "source": [
    "# Step 7: It's finally time for sentence generation!\n",
    "\n",
    "\n",
    "We are now ready to implement an algorithm that generates a sentence about cooking. This will be achieved by searching through the space of all possible sentences in order to find and output a sentence about cooking. \n",
    "\n",
    "As discussed in the presentation the task above is called an optimisation problem. There are many different search strategies that can be employed to solve this task. Here we will employ the simplest possible strategy: Random guessing. \n",
    "\n",
    "Before we implement the random guessing algorithm we describe two helper functions. The details of how these are implemented are not important, but their input output behaviour is:\n",
    "\n",
    "1. The `_create_sentence_searc_space()` function takes in no inputs and returns a list of all the sentences in our search space. \n",
    "2. The `_measure_quantum_circuit_for_sentence(sentence)` function takes in a sentence in the search space and measures the corresponding paraemterised quantum circuit, returning an array of two numbers between 0 and 1, which add up to 1. The first number represents the probability that the given sentence is about food, while the second number represents the probability that it is about IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8_q4A-R5dqR"
   },
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "def _create_sentence_search_space():\n",
    "    MC_GRAMMAR = \"\"\"\n",
    "      S -> NP VP\n",
    "      NP -> N\n",
    "      VP -> V NP\n",
    "      NP -> A N\n",
    "      A -> 'skillful' | 'tasty' | 'useful'\n",
    "      N -> 'application' | 'dinner' | 'man' | 'meal' | 'person' | 'program' | 'sauce' | 'software' | 'woman'\n",
    "      V -> 'bakes' | 'cooks' | 'debugs' | 'prepares' | 'runs'\n",
    "      \"\"\"\n",
    "\n",
    "    VOCAB = ['debugs', 'dinner', 'person', 'useful', 'runs', 'program', 'bakes', 'cooks', 'skillful', 'woman', 'prepares', 'application', 'man', 'software', 'sauce', 'meal', 'tasty']\n",
    "\n",
    "    subjects = [\"man\", \"woman\", \"person\"]\n",
    "    objects = [\"sauce\", \"meal\", \"application\", \"software\", \"dinner\", \"program\"]\n",
    "\n",
    "    GRAMMAR = CFG.fromstring(MC_GRAMMAR)\n",
    "    SENTENCES = list(generate(GRAMMAR))\n",
    "\n",
    "    def filter_sentence(sentence):\n",
    "        # Make sure no word appears more than once:\n",
    "        if not len(set(sentence)) == len(sentence):\n",
    "            return False\n",
    "\n",
    "        # Make sure subject appears before object:\n",
    "        try:\n",
    "            subject_position = next(i for i,v in enumerate(sentence) if v in subjects)\n",
    "            object_position = next(i for i,v in enumerate(sentence) if v in objects)\n",
    "        except:\n",
    "            return False\n",
    "        return subject_position < object_position\n",
    "\n",
    "    SENTENCES = list(filter(filter_sentence, SENTENCES))\n",
    "    return SENTENCES\n",
    "\n",
    "def _measure_quantum_circuit_for_sentence(sentence):\n",
    "    parser = BobcatParser(verbose='text')\n",
    "    diagram = parser.sentences2diagrams([sentence])\n",
    "    circ = [ansatz(d) for d in diagram]\n",
    "\n",
    "    return model.get_diagram_output(circ)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfAA1bHL5dqS"
   },
   "source": [
    "### Generation assignment: Complete the  randomly_generate_sentence_with_topic function below. It's behaviour should be to continously guess a random sentence from the search space and then check to see if this is with high probability a sentence about the correct topic. If such a sentence is found, it should be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qRMhl8A5dqT"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SENTENCES = ????\n",
    "def randomly_generate_sentence_with_topic(topic):\n",
    "    i = 0\n",
    "    while i < 100:\n",
    "        i += 1\n",
    "        print(i)\n",
    "        sentence = \" \".join(random.choice(SENTENCES))\n",
    "        print(sentence)\n",
    "        prediction = ?????\n",
    "        print(prediction)\n",
    "        if topic == \"Food\" and prediction[0] > 0.9:\n",
    "            return i, sentence\n",
    "            break\n",
    "        elif topic == \"IT\" and prediction[1] > 0.9:\n",
    "            return i, sentence\n",
    "            break\n",
    "    return 100, \"Max iterations reached\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLBaksjV5dqU"
   },
   "source": [
    "Let's now run the function to generate a sentence about food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGvsj2955dqV"
   },
   "outputs": [],
   "source": [
    "randomly_generate_sentence_with_topic(\"Food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9aYVOeI5dqV"
   },
   "source": [
    "# Bonus Question! (Difficult)\n",
    "Of course, random guessing is not the most efficient way of navigating through the search space of sentences! \n",
    "In fact we already saw a cleverer way of performing this task in the presentation. This method was based on the well known hill climbing algorithm: https://en.wikipedia.org/wiki/Hill_climbing\n",
    "Your task is to read about hill climbing and use your newfound knowledge to implement the sentence generation algorithm we covered in the presentation. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
